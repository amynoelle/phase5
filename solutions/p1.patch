diff -Nur ../../src/devices/timer.c src/devices/timer.c
--- ../../src/devices/timer.c	2008-08-27 08:04:38.000000000 -0400
+++ src/devices/timer.c	2008-08-27 12:42:33.000000000 -0400
@@ -24,6 +24,9 @@
    Initialized by timer_calibrate(). */
 static unsigned loops_per_tick;
 
+/* Threads waiting in timer_sleep(). */
+static struct list wait_list;
+
 static intr_handler_func timer_interrupt;
 static bool too_many_loops (unsigned loops);
 static void busy_wait (int64_t loops);
@@ -45,6 +48,8 @@
   outb (0x40, count >> 8);
 
   intr_register_ext (0x20, timer_interrupt, "8254 Timer");
+
+  list_init (&wait_list);
 }
 
 /* Calibrates loops_per_tick, used to implement brief delays. */
@@ -93,16 +98,37 @@
   return timer_ticks () - then;
 }
 
+/* Compares two threads based on their wake-up times. */
+static bool
+compare_threads_by_wakeup_time (const struct list_elem *a_,
+                                const struct list_elem *b_,
+                                void *aux UNUSED) 
+{
+  const struct thread *a = list_entry (a_, struct thread, timer_elem);
+  const struct thread *b = list_entry (b_, struct thread, timer_elem);
+
+  return a->wakeup_time < b->wakeup_time;
+}
+
 /* Sleeps for approximately TICKS timer ticks.  Interrupts must
    be turned on. */
 void
 timer_sleep (int64_t ticks) 
 {
-  int64_t start = timer_ticks ();
+  struct thread *t = thread_current ();
+
+  /* Schedule our wake-up time. */
+  t->wakeup_time = timer_ticks () + ticks;
 
+  /* Atomically insert the current thread into the wait list. */
   ASSERT (intr_get_level () == INTR_ON);
-  while (timer_elapsed (start) < ticks) 
-    thread_yield ();
+  intr_disable ();
+  list_insert_ordered (&wait_list, &t->timer_elem,
+                       compare_threads_by_wakeup_time, NULL);
+  intr_enable ();
+
+  /* Wait. */
+  sema_down (&t->timer_sema);
 }
 
 /* Sleeps for approximately MS milliseconds.  Interrupts must be
@@ -181,6 +207,17 @@
 {
   ticks++;
   thread_tick ();
+
+  while (!list_empty (&wait_list))
+    {
+      struct thread *t = list_entry (list_front (&wait_list),
+                                     struct thread, timer_elem);
+      if (ticks < t->wakeup_time) 
+        break;
+      sema_up (&t->timer_sema);
+      thread_yield_to_higher_priority ();
+      list_pop_front (&wait_list);
+    }
 }
 
 /* Returns true if LOOPS iterations waits for more than one timer
diff -Nur ../../src/tests/Make.tests src/tests/Make.tests
--- ../../src/tests/Make.tests	2007-01-11 22:07:10.000000000 -0500
+++ src/tests/Make.tests	2008-08-27 13:00:45.000000000 -0400
@@ -51,6 +51,10 @@
 # Prevent an environment variable VERBOSE from surprising us.
 VERBOSE =
 
+# Append utils directory to fall back to pintos script in source tree
+# unless user places a different script in their path.
+export PATH := $(PATH):$(SRCDIR)/utils
+
 TESTCMD = pintos -v -k -T $(TIMEOUT)
 TESTCMD += $(SIMULATOR)
 TESTCMD += $(PINTOSOPTS)
diff -Nur ../../src/threads/fixed-point.h src/threads/fixed-point.h
--- ../../src/threads/fixed-point.h	1969-12-31 19:00:00.000000000 -0500
+++ src/threads/fixed-point.h	2008-08-27 12:42:33.000000000 -0400
@@ -0,0 +1,120 @@
+#ifndef THREADS_FIXED_POINT_H
+#define THREADS_FIXED_POINT_H
+
+#include <debug.h>
+
+/* Parameters. */
+#define FIX_BITS 32             /* Total bits per fixed-point number. */
+#define FIX_P 16                /* Number of integer bits. */
+#define FIX_Q 16                /* Number of fractional bits. */
+#define FIX_F (1 << FIX_Q)      /* pow(2, FIX_Q). */
+
+#define FIX_MIN_INT (-FIX_MAX_INT)      /* Smallest representable integer. */
+#define FIX_MAX_INT ((1 << FIX_P) - 1)  /* Largest representable integer. */
+
+/* A fixed-point number. */
+typedef struct 
+  {
+    int f;
+  }
+fixed_point_t;
+
+/* Returns a fixed-point number with F as its internal value. */
+static inline fixed_point_t
+__mk_fix (int f) 
+{
+  fixed_point_t x;
+  x.f = f;
+  return x;
+}
+
+/* Returns fixed-point number corresponding to integer N. */
+static inline fixed_point_t
+fix_int (int n) 
+{
+  ASSERT (n >= FIX_MIN_INT && n <= FIX_MAX_INT);
+  return __mk_fix (n * FIX_F);
+}
+
+/* Returns fixed-point number corresponding to N divided by D. */
+static inline fixed_point_t
+fix_frac (int n, int d) 
+{
+  ASSERT (d != 0);
+  ASSERT (n / d >= FIX_MIN_INT && n / d <= FIX_MAX_INT);
+  return __mk_fix ((long long) n * FIX_F / d);
+}
+
+/* Returns X rounded to the nearest integer. */
+static inline int
+fix_round (fixed_point_t x) 
+{
+  return (x.f + FIX_F / 2) / FIX_F;
+}
+
+/* Returns X truncated down to the nearest integer. */
+static inline int
+fix_trunc (fixed_point_t x) 
+{
+  return x.f / FIX_F;
+}
+
+/* Returns X + Y. */
+static inline fixed_point_t
+fix_add (fixed_point_t x, fixed_point_t y) 
+{
+  return __mk_fix (x.f + y.f);
+}
+
+/* Returns X - Y. */
+static inline fixed_point_t
+fix_sub (fixed_point_t x, fixed_point_t y) 
+{
+  return __mk_fix (x.f - y.f);
+}
+
+/* Returns X * Y. */
+static inline fixed_point_t
+fix_mul (fixed_point_t x, fixed_point_t y) 
+{
+  return __mk_fix ((long long) x.f * y.f / FIX_F);
+}
+
+/* Returns X * N. */
+static inline fixed_point_t
+fix_scale (fixed_point_t x, int n) 
+{
+  ASSERT (n >= 0);
+  return __mk_fix (x.f * n);
+}
+
+/* Returns X / Y. */
+static inline fixed_point_t
+fix_div (fixed_point_t x, fixed_point_t y) 
+{
+  return __mk_fix ((long long) x.f * FIX_F / y.f);
+}
+
+/* Returns X / N. */
+static inline fixed_point_t
+fix_unscale (fixed_point_t x, int n) 
+{
+  ASSERT (n > 0);
+  return __mk_fix (x.f / n);
+}
+
+/* Returns 1 / X. */
+static inline fixed_point_t
+fix_inv (fixed_point_t x) 
+{
+  return fix_div (fix_int (1), x);
+}
+
+/* Returns -1 if X < Y, 0 if X == Y, 1 if X > Y. */
+static inline int
+fix_compare (fixed_point_t x, fixed_point_t y) 
+{
+  return x.f < y.f ? -1 : x.f > y.f;
+}
+
+#endif /* threads/fixed-point.h */
diff -Nur ../../src/threads/synch.c src/threads/synch.c
--- ../../src/threads/synch.c	2006-07-20 22:05:37.000000000 -0400
+++ src/threads/synch.c	2008-08-27 12:42:33.000000000 -0400
@@ -113,10 +113,28 @@
   ASSERT (sema != NULL);
 
   old_level = intr_disable ();
-  if (!list_empty (&sema->waiters)) 
-    thread_unblock (list_entry (list_pop_front (&sema->waiters),
-                                struct thread, elem));
   sema->value++;
+  if (!list_empty (&sema->waiters)) 
+    {
+      /* Find highest-priority waiting thread. */
+      struct thread *max = list_entry (list_max (&sema->waiters,
+                                                 thread_lower_priority, NULL),
+                                       struct thread, elem);
+
+      /* Remove `max' from wait list and unblock. */
+      list_remove (&max->elem);
+      thread_unblock (max);
+
+      /* Yield to a higher-priority thread, if we're running in a
+         context where it makes sense to do so.
+         
+         Kind of a funny interaction with donation here.
+         We only support donation for locks, and locks turn off
+         interrupts before calling us, so we automatically don't
+         do the yield here, delegating to lock_release(). */
+      if (!intr_context () && old_level == INTR_ON)
+        thread_yield_to_higher_priority ();
+    }
   intr_set_level (old_level);
 }
 
@@ -192,12 +210,33 @@
 void
 lock_acquire (struct lock *lock)
 {
+  enum intr_level old_level;
+
   ASSERT (lock != NULL);
   ASSERT (!intr_context ());
   ASSERT (!lock_held_by_current_thread (lock));
 
+  old_level = intr_disable ();
+
+  if (lock->holder != NULL) 
+    {
+      /* Donate our priority to the thread holding the lock.
+         First, update the data structures. */
+      struct thread *donor = thread_current ();
+      donor->want_lock = lock;
+      donor->donee = lock->holder;
+      list_push_back (&lock->holder->donors, &donor->donor_elem);
+      
+      /* Now implement the priority donation itself
+         by recomputing the donee's priority
+         and cascading the donation as far as necessary. */
+      if (donor->donee != NULL)
+        thread_recompute_priority (donor->donee);
+    }
+
   sema_down (&lock->semaphore);
   lock->holder = thread_current ();
+  intr_set_level (old_level);
 }
 
 /* Tries to acquires LOCK and returns true if successful or false
@@ -228,11 +267,39 @@
 void
 lock_release (struct lock *lock) 
 {
+  enum intr_level old_level;
+  struct thread *t = thread_current ();
+  struct list_elem *e;
+
   ASSERT (lock != NULL);
   ASSERT (lock_held_by_current_thread (lock));
 
+  old_level = intr_disable ();
+
+  /* Return donations to threads that want this lock. */
+  for (e = list_begin (&t->donors); e != list_end (&t->donors); ) 
+    {
+      struct thread *donor = list_entry (e, struct thread, donor_elem);
+      if (donor->want_lock == lock) 
+        {
+          donor->donee = NULL;
+          e = list_remove (e);
+        }
+      else
+        e = list_next (e);
+    }
+
+  /* Release lock. */
   lock->holder = NULL;
   sema_up (&lock->semaphore);
+
+  /* Recompute our priority based on our remaining donations,
+     then yield to a higher-priority ready thread if one now
+     exists. */
+  thread_recompute_priority (t);
+  thread_yield_to_higher_priority ();
+
+  intr_set_level (old_level);
 }
 
 /* Returns true if the current thread holds LOCK, false
@@ -251,6 +318,7 @@
   {
     struct list_elem elem;              /* List element. */
     struct semaphore semaphore;         /* This semaphore. */
+    struct thread *thread;              /* Thread. */
   };
 
 /* Initializes condition variable COND.  A condition variable
@@ -295,12 +363,26 @@
   ASSERT (lock_held_by_current_thread (lock));
   
   sema_init (&waiter.semaphore, 0);
+  waiter.thread = thread_current ();
   list_push_back (&cond->waiters, &waiter.elem);
   lock_release (lock);
   sema_down (&waiter.semaphore);
   lock_acquire (lock);
 }
 
+static bool
+semaphore_elem_lower_priority (const struct list_elem *a_,
+                               const struct list_elem *b_,
+                               void *aux UNUSED) 
+{
+  const struct semaphore_elem *a
+    = list_entry (a_, struct semaphore_elem, elem);
+  const struct semaphore_elem *b
+    = list_entry (b_, struct semaphore_elem, elem);
+
+  return a->thread->priority < b->thread->priority;
+}
+
 /* If any threads are waiting on COND (protected by LOCK), then
    this function signals one of them to wake up from its wait.
    LOCK must be held before calling this function.
@@ -317,8 +399,12 @@
   ASSERT (lock_held_by_current_thread (lock));
 
   if (!list_empty (&cond->waiters)) 
-    sema_up (&list_entry (list_pop_front (&cond->waiters),
-                          struct semaphore_elem, elem)->semaphore);
+    {
+      struct list_elem *max
+        = list_max (&cond->waiters, semaphore_elem_lower_priority, NULL);
+      list_remove (max);
+      sema_up (&list_entry (max, struct semaphore_elem, elem)->semaphore); 
+    }
 }
 
 /* Wakes up all threads, if any, waiting on COND (protected by
diff -Nur ../../src/threads/thread.c src/threads/thread.c
--- ../../src/threads/thread.c	2008-08-27 13:06:01.000000000 -0400
+++ src/threads/thread.c	2008-08-27 13:14:12.000000000 -0400
@@ -5,11 +5,13 @@
 #include <stdio.h>
 #include <string.h>
 #include "threads/flags.h"
+#include "threads/init.h"
 #include "threads/interrupt.h"
 #include "threads/intr-stubs.h"
 #include "threads/palloc.h"
 #include "threads/switch.h"
 #include "threads/synch.h"
+#include "devices/timer.h"
 #include "threads/vaddr.h"
 #ifdef USERPROG
 #include "userprog/process.h"
@@ -53,6 +55,7 @@
 /* Scheduling. */
 #define TIME_SLICE 4            /* # of timer ticks to give each thread. */
 static unsigned thread_ticks;   /* # of timer ticks since last yield. */
+static fixed_point_t load_avg;  /* Load average. */
 
 /* If false (default), use round-robin scheduler.
    If true, use multi-level feedback queue scheduler.
@@ -92,6 +95,7 @@
   lock_init (&tid_lock);
   list_init (&ready_list);
   list_init (&all_list);
+  load_avg = fix_int (0);
 
   /* Set up a thread structure for the running thread. */
   initial_thread = running_thread ();
@@ -117,6 +121,18 @@
   sema_down (&idle_started);
 }
 
+/* Adjust recent CPU of a thread based on load factor
+   and recompute its priority. */
+static void
+adjust_recent_cpu (struct thread *t, void *aux)
+{
+  fixed_point_t load_factor = *(fixed_point_t *)aux;
+
+  t->recent_cpu = fix_add (fix_mul (load_factor, t->recent_cpu),
+                           fix_int (t->nice));
+  thread_recompute_priority (t);
+}
+
 /* Called by the timer interrupt handler at each timer tick.
    Thus, this function runs in an external interrupt context. */
 void
@@ -134,9 +150,41 @@
   else
     kernel_ticks++;
 
-  /* Enforce preemption. */
-  if (++thread_ticks >= TIME_SLICE)
-    intr_yield_on_return ();
+  if (thread_mlfqs) 
+    {
+      /* Update load average. */
+      if (timer_ticks () % TIMER_FREQ == 0) 
+        {
+          size_t ready_threads = list_size (&ready_list);
+          if (t != idle_thread)
+            ready_threads++;
+
+          load_avg = fix_add (fix_mul (fix_frac (59, 60), load_avg),
+                              fix_mul (fix_frac (1, 60), fix_int (ready_threads)));
+        }
+
+      /* Increment running process's recent_cpu. */
+      if (t != idle_thread)
+        t->recent_cpu = fix_add (t->recent_cpu, fix_int (1));
+
+      /* Update recent_cpu and thread priorities once per second. */
+      if (timer_ticks () % TIMER_FREQ == 0) 
+        {
+          fixed_point_t twice_load = fix_scale (load_avg, 2);
+          fixed_point_t twice_load_plus_1 = fix_add (twice_load, fix_int (1));
+          fixed_point_t load_factor = fix_div (twice_load, twice_load_plus_1);
+
+          thread_foreach (adjust_recent_cpu, &load_factor);
+        }
+    }
+
+  /* Switch threads if time slice has expired. */
+  if (++thread_ticks >= TIME_SLICE) 
+    {
+      if (thread_mlfqs)
+        thread_recompute_priority (thread_current ());
+      intr_yield_on_return (); 
+    }
 }
 
 /* Prints thread statistics. */
@@ -166,12 +214,13 @@
 thread_create (const char *name, int priority,
                thread_func *function, void *aux) 
 {
+  struct thread *cur = thread_current ();
   struct thread *t;
   struct kernel_thread_frame *kf;
   struct switch_entry_frame *ef;
   struct switch_threads_frame *sf;
-  tid_t tid;
   enum intr_level old_level;
+  tid_t tid;
 
   ASSERT (function != NULL);
 
@@ -181,8 +230,10 @@
     return TID_ERROR;
 
   /* Initialize thread. */
-  init_thread (t, name, priority);
+  init_thread (t, name, thread_mlfqs ? cur->priority : priority);
   tid = t->tid = allocate_tid ();
+  t->nice = cur->nice;
+  t->recent_cpu = cur->recent_cpu;
 
   /* Prepare thread for first run by initializing its stack.
      Do this atomically so intermediate values for the 'stack' 
@@ -208,6 +259,8 @@
 
   /* Add to run queue. */
   thread_unblock (t);
+  if (priority > thread_get_priority ())
+    thread_yield ();
 
   return tid;
 }
@@ -228,6 +281,19 @@
   schedule ();
 }
 
+/* Returns true if A has lower priority than B,
+   within a list of threads. */
+bool
+thread_lower_priority (const struct list_elem *a_,
+                        const struct list_elem *b_,
+                        void *aux UNUSED) 
+{
+  const struct thread *a = list_entry (a_, struct thread, elem);
+  const struct thread *b = list_entry (b_, struct thread, elem);
+
+  return a->priority < b->priority;
+}
+
 /* Transitions a blocked thread T to the ready-to-run state.
    This is an error if T is not blocked.  (Use thread_yield() to
    make the running thread ready.)
@@ -339,11 +405,26 @@
     }
 }
 
-/* Sets the current thread's priority to NEW_PRIORITY. */
+static void
+recompute_priority_chain (void) 
+{
+  enum intr_level old_level = intr_disable ();
+  thread_recompute_priority (thread_current ());
+  thread_yield_to_higher_priority ();
+  intr_set_level (old_level);
+}
+
+/* Sets the current thread's priority to PRIORITY. */
 void
-thread_set_priority (int new_priority) 
+thread_set_priority (int priority) 
 {
-  thread_current ()->priority = new_priority;
+  if (!thread_mlfqs) 
+    {
+      struct thread *t = thread_current ();
+
+      t->normal_priority = priority;
+      recompute_priority_chain ();
+    }
 }
 
 /* Returns the current thread's priority. */
@@ -355,33 +436,98 @@
 
 /* Sets the current thread's nice value to NICE. */
 void
-thread_set_nice (int nice UNUSED) 
+thread_set_nice (int nice) 
 {
-  /* Not yet implemented. */
+  thread_current ()->nice = nice;
+  recompute_priority_chain ();
 }
 
 /* Returns the current thread's nice value. */
 int
 thread_get_nice (void) 
 {
-  /* Not yet implemented. */
-  return 0;
+  return thread_current ()->nice;
 }
 
-/* Returns 100 times the system load average. */
 int
 thread_get_load_avg (void) 
 {
-  /* Not yet implemented. */
-  return 0;
+  int load_avg_int;
+  enum intr_level level = intr_disable ();
+  load_avg_int = fix_round (fix_scale (load_avg, 100));
+  intr_set_level (level);
+  return load_avg_int;
 }
 
-/* Returns 100 times the current thread's recent_cpu value. */
 int
 thread_get_recent_cpu (void) 
 {
-  /* Not yet implemented. */
-  return 0;
+  int recent_cpu_int;
+  enum intr_level level = intr_disable ();
+  recent_cpu_int = fix_round (fix_scale (thread_current ()->recent_cpu, 100));
+  intr_set_level (level);
+  return recent_cpu_int;
+}
+
+/* Returns true if thread A has lower priority than thread B,
+   within a list of donors. */
+static bool
+donated_lower_priority (const struct list_elem *a_,
+                        const struct list_elem *b_,
+                        void *aux UNUSED) 
+{
+  const struct thread *a = list_entry (a_, struct thread, donor_elem);
+  const struct thread *b = list_entry (b_, struct thread, donor_elem);
+
+  return a->priority < b->priority;
+}
+
+/* Recomputes T's priority in terms of its normal priority and
+   its donors' priorities, if any,
+   and cascades the donation as necessary. */
+void
+thread_recompute_priority (struct thread *t) 
+{
+  int old_priority = t->priority;
+  int default_priority = t->normal_priority;
+  int donation = PRI_MIN;
+  if (thread_mlfqs) 
+    {
+      default_priority = PRI_MAX - fix_round (t->recent_cpu) / 4 - t->nice * 2;
+      if (default_priority < PRI_MIN)
+        default_priority = PRI_MIN;
+      else if (default_priority > PRI_MAX)
+        default_priority = PRI_MAX; 
+    }
+  if (!list_empty (&t->donors))
+    donation = list_entry (list_max (&t->donors, donated_lower_priority, NULL),
+                           struct thread, donor_elem)->priority;
+  t->priority = donation > default_priority ? donation : default_priority;
+  if (t->priority > old_priority && t->donee != NULL)
+    thread_recompute_priority (t->donee);
+}
+
+/* If the ready list contains a thread with a higher priority,
+   yields to it. */
+void
+thread_yield_to_higher_priority (void)
+{
+  enum intr_level old_level = intr_disable ();
+  if (!list_empty (&ready_list)) 
+    {
+      struct thread *cur = thread_current ();
+      struct thread *max = list_entry (list_max (&ready_list,
+                                                 thread_lower_priority, NULL),
+                                       struct thread, elem);
+      if (max->priority > cur->priority)
+        {
+          if (intr_context ())
+            intr_yield_on_return ();
+          else
+            thread_yield (); 
+        }
+    }
+  intr_set_level (old_level);
 }
 
 /* Idle thread.  Executes when no other thread is ready to run.
@@ -467,8 +613,10 @@
   t->status = THREAD_BLOCKED;
   strlcpy (t->name, name, sizeof t->name);
   t->stack = (uint8_t *) t + PGSIZE;
-  t->priority = priority;
+  t->priority = t->normal_priority = priority;
   t->magic = THREAD_MAGIC;
+  sema_init (&t->timer_sema, 0);
+  list_init (&t->donors);
   list_push_back (&all_list, &t->allelem);
 }
 
@@ -495,8 +643,14 @@
 {
   if (list_empty (&ready_list))
     return idle_thread;
-  else
-    return list_entry (list_pop_front (&ready_list), struct thread, elem);
+  else 
+    {
+      struct thread *max
+        = list_entry (list_max (&ready_list, thread_lower_priority, NULL),
+                      struct thread, elem);
+      list_remove (&max->elem);
+      return max;
+    }
 }
 
 /* Completes a thread switch by activating the new thread's page
diff -Nur ../../src/threads/thread.h src/threads/thread.h
--- ../../src/threads/thread.h	2008-08-27 08:45:26.000000000 -0400
+++ src/threads/thread.h	2008-08-27 12:45:31.000000000 -0400
@@ -4,6 +4,8 @@
 #include <debug.h>
 #include <list.h>
 #include <stdint.h>
+#include "threads/synch.h"
+#include "threads/fixed-point.h"
 
 /* States in a thread's life cycle. */
 enum thread_status
@@ -87,12 +89,26 @@
     enum thread_status status;          /* Thread state. */
     char name[16];                      /* Name (for debugging purposes). */
     uint8_t *stack;                     /* Saved stack pointer. */
-    int priority;                       /* Priority. */
+
+    /* Scheduler data. */
+    int priority;                       /* Priority, including donations. */
+    int normal_priority;                /* Priority, without donations. */
+    struct list donors;                 /* Threads donating priority to us. */
+    struct list_elem donor_elem;        /* Element in donors list. */
+    struct thread *donee;               /* Thread we're donating to. */
+    struct lock *want_lock;             /* Lock we're waiting to acquire. */
+    int nice;                           /* Niceness. */
+    fixed_point_t recent_cpu;           /* Recent amount of CPU time. */    
     struct list_elem allelem;           /* List element for all threads list. */
 
     /* Shared between thread.c and synch.c. */
     struct list_elem elem;              /* List element. */
 
+    /* Alarm clock. */
+    int64_t wakeup_time;                /* Time to wake this thread up. */
+    struct list_elem timer_elem;        /* Element in wait_list. */
+    struct semaphore timer_sema;        /* Semaphore. */
+ 
 #ifdef USERPROG
     /* Owned by userprog/process.c. */
     uint32_t *pagedir;                  /* Page directory. */
@@ -125,6 +141,10 @@
 
 void thread_exit (void) NO_RETURN;
 void thread_yield (void);
+void thread_yield_to_higher_priority (void);
+void thread_recompute_priority (struct thread *);
+bool thread_lower_priority (const struct list_elem *, const struct list_elem *,
+                            void *aux);
 
 /* Performs some operation on thread t, given auxiliary data AUX. */
 typedef void thread_action_func (struct thread *t, void *aux);
